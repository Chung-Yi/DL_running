{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Day43_define_network_HW.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf8-JeeLeoPO",
        "colab_type": "text"
      },
      "source": [
        "### 作業\n",
        "請嘗試使用 keras 來定義一個直接預測 15 個人臉關鍵點坐標的檢測網路，以及適合這個網路的 loss function\n",
        "\n",
        "\n",
        "Hint: 參考前面的電腦視覺深度學習基礎"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eVvfFuseoPR",
        "colab_type": "text"
      },
      "source": [
        "### 範例\n",
        "接下來的程式碼會示範如何定義一個簡單的 CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gACMKQ1_eoPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhk8eM-jeoPW",
        "colab_type": "code",
        "outputId": "1e700784-6c5d-4c73-8e1f-8988503cccc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "# 使用 colab 環境的同學請執行以下程式碼\n",
        "%tensorflow_version 1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import os\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive') # 將 google drive 掛載在 colob，\n",
        "%cd 'gdrive/My Drive'\n",
        "os.system(\"mkdir cupoy_cv_part4\") # 可以自己改路徑\n",
        "%cd cupoy_cv_part4 # 可以自己改路徑"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "1.15.0\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive\n",
            "[Errno 2] No such file or directory: 'cupoy_cv_part4 # 可以自己改路徑'\n",
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXUtAK6qeoPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 讀取資料集以及做前處理的函數\n",
        "def load_data(dirname):\n",
        "    # 讀取 csv 文件\n",
        "    data = pd.read_csv(dirname)\n",
        "    # 過濾有缺失值的 row\n",
        "    data = data.dropna()\n",
        "\n",
        "    # 將圖片像素值讀取為 numpy array 的形態\n",
        "    data['Image'] = data['Image'].apply(lambda img: np.fromstring(img, sep=' ')).values \n",
        "\n",
        "    # 單獨把圖像 array 抽取出來\n",
        "    imgs = np.vstack(data['Image'].values)/255\n",
        "    # reshape 為 96 x 96\n",
        "    imgs = imgs.reshape(data.shape[0], 96, 96)\n",
        "    # 轉換為 float\n",
        "    imgs = imgs.astype(np.float32)\n",
        "    \n",
        "    # 提取坐標的部分\n",
        "    points = data[data.columns[:-1]].values\n",
        "\n",
        "    # 轉換為 float\n",
        "    points = points.astype(np.float32)\n",
        "\n",
        "    # normalize 坐標值到 [-0.5, 0.5]\n",
        "    points = points/96 - 0.5\n",
        "    \n",
        "    return imgs, points"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYJwus-FeuQR",
        "colab_type": "code",
        "outputId": "a1b7d8bc-f494-4cd4-e93e-e37801031803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd D43"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/D43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Adt9VJVdeoPc",
        "colab_type": "code",
        "outputId": "6dafb3d2-8443-48be-8a5e-a5bd6b966fe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# 讀取資料\n",
        "imgs_train, points_train = load_data(dirname = 'training.csv')\n",
        "print(\"圖像資料:\", imgs_train.shape, \"\\n關鍵點資料:\", points_train.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "圖像資料: (2140, 96, 96) \n",
            "關鍵點資料: (2140, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qZD7RbNeoPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs_train = np.expand_dims(imgs_train, axis=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZolCx0DxeoPi",
        "colab_type": "code",
        "outputId": "0a0d19de-dcb6-4cfb-d51f-cce802b414aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "imgs_train.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2140, 96, 96, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ma3sn5GeoPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5af56445-44c8-441f-a123-693578017007"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, MaxPool2D, BatchNormalization, Input, Activation\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.models import Model"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6qcJSEmeoPr",
        "colab_type": "code",
        "outputId": "49b80007-e853-422c-bb90-bedeb4236f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "# 定義人臉關鍵點檢測網路\n",
        "input_shape = Input((96, 96, 1))\n",
        "\n",
        "model = Conv2D(32, (3, 3), padding=\"same\")(input_shape)\n",
        "model = BatchNormalization(axis=-1)(model)\n",
        "model = Activation(\"relu\")(model)\n",
        "model = MaxPooling2D(pool_size=(2, 2))(model)\n",
        "\n",
        "model = Conv2D(64, (3, 3), padding=\"same\")(input_shape)\n",
        "model = BatchNormalization(axis=-1)(model)\n",
        "model = Activation(\"relu\")(model)\n",
        "model = Conv2D(64, (3, 3), padding=\"same\")(input_shape)\n",
        "model = BatchNormalization(axis=-1)(model)\n",
        "model = Activation(\"relu\")(model)\n",
        "model = MaxPooling2D(pool_size=(2, 2))(model)\n",
        "\n",
        "# model = Conv2D(128, (3, 3), padding=\"same\")(input_shape)\n",
        "# model = BatchNormalization(axis=-1)(model)\n",
        "# model = Activation(\"relu\")(model)\n",
        "# model = Conv2D(128, (3, 3), padding=\"same\")(input_shape)\n",
        "# model = BatchNormalization(axis=-1)(model)\n",
        "# model = Activation(\"relu\")(model)\n",
        "# model = MaxPooling2D(pool_size=(2, 2))(model)\n",
        "\n",
        "model = Flatten()(model)\n",
        "model = Dense(256)(model)\n",
        "model = BatchNormalization()(model)\n",
        "model = Activation(\"relu\")(model)\n",
        "model = Dense(30, activation=None, use_bias=True)(model)\n",
        "\n",
        "model = Model(inputs=input_shape, outputs=model)\n",
        "\n",
        "# 定義神經網路的輸入, hidden layer 以及輸出\n",
        "\n",
        "# 配置 loss funtion 和 optimizer\n",
        "# model.compile(loss='', optimizer='')\n",
        "model.summary()\n",
        "adam = Adam(lr=0.001)\n",
        "#     sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
        "model.compile(\n",
        "    loss='mean_squared_error', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 96, 96, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 96, 96, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 96, 96, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 96, 96, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 147456)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               37748992  \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 30)                7710      \n",
            "=================================================================\n",
            "Total params: 37,758,622\n",
            "Trainable params: 37,757,982\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmMNp1dBeoP0",
        "colab_type": "code",
        "outputId": "822ecd32-49d5-4193-ddab-c672fb7bbed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(\n",
        "        imgs_train,\n",
        "        points_train,\n",
        "        validation_split=0.2,\n",
        "        epochs=500,\n",
        "        batch_size=32,\n",
        "        verbose=2)\n",
        "\n",
        "model.save('points_model.h5')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1712 samples, validate on 428 samples\n",
            "Epoch 1/500\n",
            " - 4s - loss: 0.0092 - acc: 0.4433 - val_loss: 0.0969 - val_acc: 0.0607\n",
            "Epoch 2/500\n",
            " - 4s - loss: 0.0048 - acc: 0.5491 - val_loss: 0.0415 - val_acc: 0.0888\n",
            "Epoch 3/500\n",
            " - 4s - loss: 0.0032 - acc: 0.5964 - val_loss: 0.0289 - val_acc: 0.1145\n",
            "Epoch 4/500\n",
            " - 4s - loss: 0.0025 - acc: 0.6484 - val_loss: 0.0199 - val_acc: 0.1402\n",
            "Epoch 5/500\n",
            " - 4s - loss: 0.0020 - acc: 0.6822 - val_loss: 0.0099 - val_acc: 0.2290\n",
            "Epoch 6/500\n",
            " - 4s - loss: 0.0017 - acc: 0.6834 - val_loss: 0.0063 - val_acc: 0.2266\n",
            "Epoch 7/500\n",
            " - 4s - loss: 0.0013 - acc: 0.7249 - val_loss: 0.0054 - val_acc: 0.2453\n",
            "Epoch 8/500\n",
            " - 4s - loss: 0.0012 - acc: 0.7377 - val_loss: 0.0048 - val_acc: 0.2757\n",
            "Epoch 9/500\n",
            " - 4s - loss: 0.0011 - acc: 0.7383 - val_loss: 0.0048 - val_acc: 0.1916\n",
            "Epoch 10/500\n",
            " - 4s - loss: 9.9815e-04 - acc: 0.7488 - val_loss: 0.0040 - val_acc: 0.2640\n",
            "Epoch 11/500\n",
            " - 4s - loss: 0.0010 - acc: 0.7558 - val_loss: 0.0036 - val_acc: 0.3949\n",
            "Epoch 12/500\n",
            " - 4s - loss: 8.2237e-04 - acc: 0.7704 - val_loss: 0.0032 - val_acc: 0.3224\n",
            "Epoch 13/500\n",
            " - 4s - loss: 7.1729e-04 - acc: 0.7593 - val_loss: 0.0033 - val_acc: 0.4112\n",
            "Epoch 14/500\n",
            " - 4s - loss: 7.2082e-04 - acc: 0.7687 - val_loss: 0.0030 - val_acc: 0.4089\n",
            "Epoch 15/500\n",
            " - 4s - loss: 6.3115e-04 - acc: 0.7751 - val_loss: 0.0026 - val_acc: 0.4182\n",
            "Epoch 16/500\n",
            " - 4s - loss: 6.2696e-04 - acc: 0.8061 - val_loss: 0.0030 - val_acc: 0.3808\n",
            "Epoch 17/500\n",
            " - 4s - loss: 5.8799e-04 - acc: 0.7973 - val_loss: 0.0025 - val_acc: 0.4439\n",
            "Epoch 18/500\n",
            " - 4s - loss: 5.3063e-04 - acc: 0.8125 - val_loss: 0.0025 - val_acc: 0.4463\n",
            "Epoch 19/500\n",
            " - 4s - loss: 5.0119e-04 - acc: 0.8084 - val_loss: 0.0023 - val_acc: 0.4182\n",
            "Epoch 20/500\n",
            " - 4s - loss: 4.5268e-04 - acc: 0.8178 - val_loss: 0.0021 - val_acc: 0.4369\n",
            "Epoch 21/500\n",
            " - 4s - loss: 4.7070e-04 - acc: 0.8078 - val_loss: 0.0023 - val_acc: 0.4439\n",
            "Epoch 22/500\n",
            " - 4s - loss: 4.3994e-04 - acc: 0.8143 - val_loss: 0.0025 - val_acc: 0.4696\n",
            "Epoch 23/500\n",
            " - 4s - loss: 4.3924e-04 - acc: 0.8084 - val_loss: 0.0021 - val_acc: 0.4696\n",
            "Epoch 24/500\n",
            " - 4s - loss: 4.1739e-04 - acc: 0.8236 - val_loss: 0.0020 - val_acc: 0.5093\n",
            "Epoch 25/500\n",
            " - 4s - loss: 3.7780e-04 - acc: 0.8329 - val_loss: 0.0018 - val_acc: 0.5023\n",
            "Epoch 26/500\n",
            " - 4s - loss: 3.7603e-04 - acc: 0.8300 - val_loss: 0.0020 - val_acc: 0.4883\n",
            "Epoch 27/500\n",
            " - 4s - loss: 3.7933e-04 - acc: 0.8283 - val_loss: 0.0019 - val_acc: 0.4860\n",
            "Epoch 28/500\n",
            " - 4s - loss: 3.8841e-04 - acc: 0.8183 - val_loss: 0.0019 - val_acc: 0.4463\n",
            "Epoch 29/500\n",
            " - 4s - loss: 3.6204e-04 - acc: 0.8277 - val_loss: 0.0019 - val_acc: 0.4673\n",
            "Epoch 30/500\n",
            " - 4s - loss: 3.8445e-04 - acc: 0.8364 - val_loss: 0.0018 - val_acc: 0.4579\n",
            "Epoch 31/500\n",
            " - 4s - loss: 4.0670e-04 - acc: 0.8061 - val_loss: 0.0019 - val_acc: 0.4346\n",
            "Epoch 32/500\n",
            " - 4s - loss: 3.8336e-04 - acc: 0.8178 - val_loss: 0.0018 - val_acc: 0.4860\n",
            "Epoch 33/500\n",
            " - 4s - loss: 3.5337e-04 - acc: 0.8318 - val_loss: 0.0017 - val_acc: 0.5093\n",
            "Epoch 34/500\n",
            " - 4s - loss: 3.4830e-04 - acc: 0.8405 - val_loss: 0.0018 - val_acc: 0.4603\n",
            "Epoch 35/500\n",
            " - 4s - loss: 3.2699e-04 - acc: 0.8382 - val_loss: 0.0018 - val_acc: 0.4977\n",
            "Epoch 36/500\n",
            " - 4s - loss: 3.2179e-04 - acc: 0.8411 - val_loss: 0.0016 - val_acc: 0.4836\n",
            "Epoch 37/500\n",
            " - 4s - loss: 3.1843e-04 - acc: 0.8055 - val_loss: 0.0017 - val_acc: 0.4930\n",
            "Epoch 38/500\n",
            " - 4s - loss: 3.3548e-04 - acc: 0.8429 - val_loss: 0.0017 - val_acc: 0.4533\n",
            "Epoch 39/500\n",
            " - 4s - loss: 3.0349e-04 - acc: 0.8394 - val_loss: 0.0016 - val_acc: 0.4650\n",
            "Epoch 40/500\n",
            " - 4s - loss: 3.2415e-04 - acc: 0.8435 - val_loss: 0.0017 - val_acc: 0.4463\n",
            "Epoch 41/500\n",
            " - 4s - loss: 3.2159e-04 - acc: 0.8324 - val_loss: 0.0016 - val_acc: 0.5047\n",
            "Epoch 42/500\n",
            " - 4s - loss: 3.4132e-04 - acc: 0.8528 - val_loss: 0.0018 - val_acc: 0.4836\n",
            "Epoch 43/500\n",
            " - 4s - loss: 3.6316e-04 - acc: 0.8505 - val_loss: 0.0016 - val_acc: 0.4883\n",
            "Epoch 44/500\n",
            " - 4s - loss: 3.3795e-04 - acc: 0.8172 - val_loss: 0.0016 - val_acc: 0.4930\n",
            "Epoch 45/500\n",
            " - 4s - loss: 3.2393e-04 - acc: 0.8335 - val_loss: 0.0017 - val_acc: 0.4486\n",
            "Epoch 46/500\n",
            " - 4s - loss: 2.9298e-04 - acc: 0.8505 - val_loss: 0.0015 - val_acc: 0.4533\n",
            "Epoch 47/500\n",
            " - 4s - loss: 3.9773e-04 - acc: 0.8318 - val_loss: 0.0018 - val_acc: 0.4416\n",
            "Epoch 48/500\n",
            " - 4s - loss: 3.7339e-04 - acc: 0.8458 - val_loss: 0.0016 - val_acc: 0.5047\n",
            "Epoch 49/500\n",
            " - 4s - loss: 3.5668e-04 - acc: 0.8271 - val_loss: 0.0015 - val_acc: 0.4112\n",
            "Epoch 50/500\n",
            " - 4s - loss: 2.8815e-04 - acc: 0.8522 - val_loss: 0.0015 - val_acc: 0.4696\n",
            "Epoch 51/500\n",
            " - 4s - loss: 2.5693e-04 - acc: 0.8464 - val_loss: 0.0015 - val_acc: 0.4743\n",
            "Epoch 52/500\n",
            " - 4s - loss: 2.8319e-04 - acc: 0.8213 - val_loss: 0.0015 - val_acc: 0.4159\n",
            "Epoch 53/500\n",
            " - 4s - loss: 3.0893e-04 - acc: 0.8300 - val_loss: 0.0016 - val_acc: 0.4603\n",
            "Epoch 54/500\n",
            " - 4s - loss: 3.4294e-04 - acc: 0.8259 - val_loss: 0.0015 - val_acc: 0.4836\n",
            "Epoch 55/500\n",
            " - 4s - loss: 3.4101e-04 - acc: 0.8289 - val_loss: 0.0016 - val_acc: 0.4930\n",
            "Epoch 56/500\n",
            " - 4s - loss: 3.4109e-04 - acc: 0.8516 - val_loss: 0.0017 - val_acc: 0.4930\n",
            "Epoch 57/500\n",
            " - 4s - loss: 3.9296e-04 - acc: 0.8429 - val_loss: 0.0018 - val_acc: 0.5117\n",
            "Epoch 58/500\n",
            " - 4s - loss: 3.3313e-04 - acc: 0.8470 - val_loss: 0.0016 - val_acc: 0.4720\n",
            "Epoch 59/500\n",
            " - 4s - loss: 2.8531e-04 - acc: 0.8487 - val_loss: 0.0015 - val_acc: 0.4322\n",
            "Epoch 60/500\n",
            " - 4s - loss: 3.1043e-04 - acc: 0.8329 - val_loss: 0.0015 - val_acc: 0.4650\n",
            "Epoch 61/500\n",
            " - 4s - loss: 2.9532e-04 - acc: 0.8563 - val_loss: 0.0015 - val_acc: 0.5000\n",
            "Epoch 62/500\n",
            " - 4s - loss: 3.2219e-04 - acc: 0.8668 - val_loss: 0.0016 - val_acc: 0.5164\n",
            "Epoch 63/500\n",
            " - 4s - loss: 3.0059e-04 - acc: 0.8493 - val_loss: 0.0016 - val_acc: 0.4463\n",
            "Epoch 64/500\n",
            " - 4s - loss: 3.1943e-04 - acc: 0.8645 - val_loss: 0.0015 - val_acc: 0.5047\n",
            "Epoch 65/500\n",
            " - 4s - loss: 3.3095e-04 - acc: 0.8440 - val_loss: 0.0016 - val_acc: 0.4673\n",
            "Epoch 66/500\n",
            " - 4s - loss: 3.3526e-04 - acc: 0.8464 - val_loss: 0.0015 - val_acc: 0.4650\n",
            "Epoch 67/500\n",
            " - 4s - loss: 3.1532e-04 - acc: 0.8458 - val_loss: 0.0016 - val_acc: 0.4509\n",
            "Epoch 68/500\n",
            " - 4s - loss: 2.8899e-04 - acc: 0.8277 - val_loss: 0.0014 - val_acc: 0.4696\n",
            "Epoch 69/500\n",
            " - 4s - loss: 2.8370e-04 - acc: 0.8528 - val_loss: 0.0016 - val_acc: 0.4579\n",
            "Epoch 70/500\n",
            " - 4s - loss: 3.3089e-04 - acc: 0.8388 - val_loss: 0.0018 - val_acc: 0.4720\n",
            "Epoch 71/500\n",
            " - 4s - loss: 3.8296e-04 - acc: 0.8329 - val_loss: 0.0015 - val_acc: 0.4416\n",
            "Epoch 72/500\n",
            " - 4s - loss: 3.9765e-04 - acc: 0.8440 - val_loss: 0.0016 - val_acc: 0.4463\n",
            "Epoch 73/500\n",
            " - 4s - loss: 4.0512e-04 - acc: 0.8183 - val_loss: 0.0018 - val_acc: 0.4463\n",
            "Epoch 74/500\n",
            " - 4s - loss: 3.6358e-04 - acc: 0.8499 - val_loss: 0.0017 - val_acc: 0.4322\n",
            "Epoch 75/500\n",
            " - 4s - loss: 3.7444e-04 - acc: 0.8569 - val_loss: 0.0017 - val_acc: 0.4626\n",
            "Epoch 76/500\n",
            " - 4s - loss: 3.9385e-04 - acc: 0.8300 - val_loss: 0.0015 - val_acc: 0.5000\n",
            "Epoch 77/500\n",
            " - 4s - loss: 3.9973e-04 - acc: 0.8394 - val_loss: 0.0017 - val_acc: 0.4907\n",
            "Epoch 78/500\n",
            " - 4s - loss: 4.1055e-04 - acc: 0.8230 - val_loss: 0.0015 - val_acc: 0.4603\n",
            "Epoch 79/500\n",
            " - 4s - loss: 3.8032e-04 - acc: 0.8464 - val_loss: 0.0016 - val_acc: 0.4322\n",
            "Epoch 80/500\n",
            " - 4s - loss: 3.2216e-04 - acc: 0.8370 - val_loss: 0.0015 - val_acc: 0.4953\n",
            "Epoch 81/500\n",
            " - 4s - loss: 3.0843e-04 - acc: 0.8481 - val_loss: 0.0016 - val_acc: 0.4766\n",
            "Epoch 82/500\n",
            " - 4s - loss: 3.1162e-04 - acc: 0.8604 - val_loss: 0.0015 - val_acc: 0.4112\n",
            "Epoch 83/500\n",
            " - 4s - loss: 3.3147e-04 - acc: 0.8429 - val_loss: 0.0014 - val_acc: 0.4509\n",
            "Epoch 84/500\n",
            " - 4s - loss: 3.4302e-04 - acc: 0.8581 - val_loss: 0.0014 - val_acc: 0.4439\n",
            "Epoch 85/500\n",
            " - 4s - loss: 3.5111e-04 - acc: 0.8405 - val_loss: 0.0016 - val_acc: 0.4276\n",
            "Epoch 86/500\n",
            " - 4s - loss: 3.3134e-04 - acc: 0.8294 - val_loss: 0.0015 - val_acc: 0.4860\n",
            "Epoch 87/500\n",
            " - 4s - loss: 3.6000e-04 - acc: 0.8470 - val_loss: 0.0016 - val_acc: 0.4930\n",
            "Epoch 88/500\n",
            " - 4s - loss: 3.8841e-04 - acc: 0.8440 - val_loss: 0.0016 - val_acc: 0.4416\n",
            "Epoch 89/500\n",
            " - 4s - loss: 3.5679e-04 - acc: 0.8107 - val_loss: 0.0018 - val_acc: 0.4650\n",
            "Epoch 90/500\n",
            " - 4s - loss: 4.0161e-04 - acc: 0.8189 - val_loss: 0.0015 - val_acc: 0.5140\n",
            "Epoch 91/500\n",
            " - 4s - loss: 3.6715e-04 - acc: 0.8236 - val_loss: 0.0018 - val_acc: 0.5000\n",
            "Epoch 92/500\n",
            " - 4s - loss: 3.3378e-04 - acc: 0.8312 - val_loss: 0.0015 - val_acc: 0.4416\n",
            "Epoch 93/500\n",
            " - 4s - loss: 4.4819e-04 - acc: 0.8014 - val_loss: 0.0017 - val_acc: 0.4463\n",
            "Epoch 94/500\n",
            " - 4s - loss: 4.0485e-04 - acc: 0.8300 - val_loss: 0.0016 - val_acc: 0.4159\n",
            "Epoch 95/500\n",
            " - 4s - loss: 3.8719e-04 - acc: 0.8411 - val_loss: 0.0017 - val_acc: 0.4743\n",
            "Epoch 96/500\n",
            " - 4s - loss: 3.2824e-04 - acc: 0.8475 - val_loss: 0.0014 - val_acc: 0.4720\n",
            "Epoch 97/500\n",
            " - 4s - loss: 3.5670e-04 - acc: 0.8329 - val_loss: 0.0015 - val_acc: 0.4206\n",
            "Epoch 98/500\n",
            " - 4s - loss: 3.4179e-04 - acc: 0.8236 - val_loss: 0.0015 - val_acc: 0.4650\n",
            "Epoch 99/500\n",
            " - 4s - loss: 3.5914e-04 - acc: 0.8639 - val_loss: 0.0016 - val_acc: 0.4089\n",
            "Epoch 100/500\n",
            " - 4s - loss: 3.8717e-04 - acc: 0.8096 - val_loss: 0.0015 - val_acc: 0.4836\n",
            "Epoch 101/500\n",
            " - 4s - loss: 3.2596e-04 - acc: 0.8435 - val_loss: 0.0017 - val_acc: 0.4533\n",
            "Epoch 102/500\n",
            " - 4s - loss: 3.4900e-04 - acc: 0.8032 - val_loss: 0.0015 - val_acc: 0.4509\n",
            "Epoch 103/500\n",
            " - 4s - loss: 3.3019e-04 - acc: 0.8376 - val_loss: 0.0016 - val_acc: 0.4696\n",
            "Epoch 104/500\n",
            " - 4s - loss: 4.3463e-04 - acc: 0.8189 - val_loss: 0.0016 - val_acc: 0.5327\n",
            "Epoch 105/500\n",
            " - 4s - loss: 3.4449e-04 - acc: 0.8440 - val_loss: 0.0016 - val_acc: 0.5117\n",
            "Epoch 106/500\n",
            " - 4s - loss: 3.9422e-04 - acc: 0.8248 - val_loss: 0.0014 - val_acc: 0.4533\n",
            "Epoch 107/500\n",
            " - 4s - loss: 3.1807e-04 - acc: 0.8586 - val_loss: 0.0015 - val_acc: 0.4439\n",
            "Epoch 108/500\n",
            " - 4s - loss: 3.2521e-04 - acc: 0.8440 - val_loss: 0.0014 - val_acc: 0.4650\n",
            "Epoch 109/500\n",
            " - 4s - loss: 3.6480e-04 - acc: 0.8382 - val_loss: 0.0015 - val_acc: 0.5187\n",
            "Epoch 110/500\n",
            " - 4s - loss: 3.5025e-04 - acc: 0.8417 - val_loss: 0.0015 - val_acc: 0.4393\n",
            "Epoch 111/500\n",
            " - 4s - loss: 3.5677e-04 - acc: 0.8440 - val_loss: 0.0014 - val_acc: 0.5187\n",
            "Epoch 112/500\n",
            " - 4s - loss: 3.2993e-04 - acc: 0.8586 - val_loss: 0.0014 - val_acc: 0.5210\n",
            "Epoch 113/500\n",
            " - 4s - loss: 3.8388e-04 - acc: 0.8061 - val_loss: 0.0016 - val_acc: 0.4790\n",
            "Epoch 114/500\n",
            " - 4s - loss: 3.6690e-04 - acc: 0.8271 - val_loss: 0.0015 - val_acc: 0.5164\n",
            "Epoch 115/500\n",
            " - 4s - loss: 4.4545e-04 - acc: 0.8072 - val_loss: 0.0016 - val_acc: 0.4533\n",
            "Epoch 116/500\n",
            " - 4s - loss: 4.6688e-04 - acc: 0.8037 - val_loss: 0.0018 - val_acc: 0.4766\n",
            "Epoch 117/500\n",
            " - 4s - loss: 3.8454e-04 - acc: 0.8335 - val_loss: 0.0017 - val_acc: 0.4346\n",
            "Epoch 118/500\n",
            " - 4s - loss: 3.1840e-04 - acc: 0.8493 - val_loss: 0.0014 - val_acc: 0.4463\n",
            "Epoch 119/500\n",
            " - 4s - loss: 3.5317e-04 - acc: 0.8341 - val_loss: 0.0015 - val_acc: 0.4393\n",
            "Epoch 120/500\n",
            " - 4s - loss: 3.7607e-04 - acc: 0.8306 - val_loss: 0.0014 - val_acc: 0.5000\n",
            "Epoch 121/500\n",
            " - 4s - loss: 3.6732e-04 - acc: 0.8160 - val_loss: 0.0015 - val_acc: 0.5047\n",
            "Epoch 122/500\n",
            " - 4s - loss: 3.8799e-04 - acc: 0.8499 - val_loss: 0.0013 - val_acc: 0.5234\n",
            "Epoch 123/500\n",
            " - 4s - loss: 3.2301e-04 - acc: 0.8388 - val_loss: 0.0014 - val_acc: 0.5210\n",
            "Epoch 124/500\n",
            " - 4s - loss: 4.1791e-04 - acc: 0.8113 - val_loss: 0.0014 - val_acc: 0.5164\n",
            "Epoch 125/500\n",
            " - 4s - loss: 3.8342e-04 - acc: 0.8119 - val_loss: 0.0016 - val_acc: 0.5164\n",
            "Epoch 126/500\n",
            " - 4s - loss: 3.5240e-04 - acc: 0.8172 - val_loss: 0.0015 - val_acc: 0.4813\n",
            "Epoch 127/500\n",
            " - 4s - loss: 3.4729e-04 - acc: 0.8423 - val_loss: 0.0015 - val_acc: 0.4977\n",
            "Epoch 128/500\n",
            " - 4s - loss: 3.5441e-04 - acc: 0.8446 - val_loss: 0.0015 - val_acc: 0.4696\n",
            "Epoch 129/500\n",
            " - 4s - loss: 3.8992e-04 - acc: 0.8102 - val_loss: 0.0013 - val_acc: 0.4743\n",
            "Epoch 130/500\n",
            " - 4s - loss: 3.7641e-04 - acc: 0.8411 - val_loss: 0.0014 - val_acc: 0.4977\n",
            "Epoch 131/500\n",
            " - 4s - loss: 3.4382e-04 - acc: 0.8633 - val_loss: 0.0014 - val_acc: 0.4463\n",
            "Epoch 132/500\n",
            " - 4s - loss: 3.9099e-04 - acc: 0.8160 - val_loss: 0.0017 - val_acc: 0.5117\n",
            "Epoch 133/500\n",
            " - 4s - loss: 3.6788e-04 - acc: 0.8347 - val_loss: 0.0014 - val_acc: 0.5187\n",
            "Epoch 134/500\n",
            " - 4s - loss: 3.6989e-04 - acc: 0.8481 - val_loss: 0.0015 - val_acc: 0.5023\n",
            "Epoch 135/500\n",
            " - 4s - loss: 3.7037e-04 - acc: 0.8388 - val_loss: 0.0014 - val_acc: 0.4533\n",
            "Epoch 136/500\n",
            " - 4s - loss: 3.6302e-04 - acc: 0.8546 - val_loss: 0.0014 - val_acc: 0.5187\n",
            "Epoch 137/500\n",
            " - 4s - loss: 3.8013e-04 - acc: 0.8557 - val_loss: 0.0013 - val_acc: 0.5350\n",
            "Epoch 138/500\n",
            " - 4s - loss: 3.2914e-04 - acc: 0.8511 - val_loss: 0.0017 - val_acc: 0.4743\n",
            "Epoch 139/500\n",
            " - 4s - loss: 3.7440e-04 - acc: 0.8487 - val_loss: 0.0016 - val_acc: 0.4533\n",
            "Epoch 140/500\n",
            " - 4s - loss: 3.1404e-04 - acc: 0.8388 - val_loss: 0.0014 - val_acc: 0.4720\n",
            "Epoch 141/500\n",
            " - 4s - loss: 3.6458e-04 - acc: 0.8423 - val_loss: 0.0013 - val_acc: 0.5047\n",
            "Epoch 142/500\n",
            " - 4s - loss: 3.7816e-04 - acc: 0.8078 - val_loss: 0.0015 - val_acc: 0.4907\n",
            "Epoch 143/500\n",
            " - 4s - loss: 3.7317e-04 - acc: 0.8277 - val_loss: 0.0014 - val_acc: 0.4533\n",
            "Epoch 144/500\n",
            " - 4s - loss: 3.0602e-04 - acc: 0.8300 - val_loss: 0.0015 - val_acc: 0.4650\n",
            "Epoch 145/500\n",
            " - 4s - loss: 4.0602e-04 - acc: 0.8254 - val_loss: 0.0014 - val_acc: 0.4720\n",
            "Epoch 146/500\n",
            " - 4s - loss: 3.3936e-04 - acc: 0.8534 - val_loss: 0.0014 - val_acc: 0.4650\n",
            "Epoch 147/500\n",
            " - 4s - loss: 2.8175e-04 - acc: 0.8820 - val_loss: 0.0014 - val_acc: 0.5280\n",
            "Epoch 148/500\n",
            " - 4s - loss: 3.4633e-04 - acc: 0.8417 - val_loss: 0.0016 - val_acc: 0.4369\n",
            "Epoch 149/500\n",
            " - 4s - loss: 3.9456e-04 - acc: 0.8224 - val_loss: 0.0014 - val_acc: 0.4930\n",
            "Epoch 150/500\n",
            " - 4s - loss: 3.8221e-04 - acc: 0.8546 - val_loss: 0.0015 - val_acc: 0.5047\n",
            "Epoch 151/500\n",
            " - 4s - loss: 3.3672e-04 - acc: 0.8563 - val_loss: 0.0014 - val_acc: 0.4416\n",
            "Epoch 152/500\n",
            " - 4s - loss: 3.2191e-04 - acc: 0.8627 - val_loss: 0.0014 - val_acc: 0.4626\n",
            "Epoch 153/500\n",
            " - 4s - loss: 3.3806e-04 - acc: 0.8213 - val_loss: 0.0013 - val_acc: 0.5117\n",
            "Epoch 154/500\n",
            " - 4s - loss: 3.4375e-04 - acc: 0.8697 - val_loss: 0.0014 - val_acc: 0.4790\n",
            "Epoch 155/500\n",
            " - 4s - loss: 3.4642e-04 - acc: 0.8709 - val_loss: 0.0013 - val_acc: 0.4953\n",
            "Epoch 156/500\n",
            " - 4s - loss: 3.5785e-04 - acc: 0.8499 - val_loss: 0.0014 - val_acc: 0.4439\n",
            "Epoch 157/500\n",
            " - 4s - loss: 3.3872e-04 - acc: 0.8505 - val_loss: 0.0015 - val_acc: 0.4463\n",
            "Epoch 158/500\n",
            " - 4s - loss: 3.7378e-04 - acc: 0.8487 - val_loss: 0.0014 - val_acc: 0.5093\n",
            "Epoch 159/500\n",
            " - 4s - loss: 3.5415e-04 - acc: 0.8429 - val_loss: 0.0014 - val_acc: 0.5327\n",
            "Epoch 160/500\n",
            " - 4s - loss: 3.5283e-04 - acc: 0.8423 - val_loss: 0.0016 - val_acc: 0.3551\n",
            "Epoch 161/500\n",
            " - 4s - loss: 3.6896e-04 - acc: 0.8499 - val_loss: 0.0014 - val_acc: 0.4720\n",
            "Epoch 162/500\n",
            " - 4s - loss: 3.0603e-04 - acc: 0.8680 - val_loss: 0.0014 - val_acc: 0.4883\n",
            "Epoch 163/500\n",
            " - 4s - loss: 4.2677e-04 - acc: 0.8125 - val_loss: 0.0015 - val_acc: 0.4322\n",
            "Epoch 164/500\n",
            " - 4s - loss: 3.5709e-04 - acc: 0.8645 - val_loss: 0.0015 - val_acc: 0.4813\n",
            "Epoch 165/500\n",
            " - 4s - loss: 3.2333e-04 - acc: 0.8534 - val_loss: 0.0014 - val_acc: 0.4977\n",
            "Epoch 166/500\n",
            " - 4s - loss: 5.3335e-04 - acc: 0.7932 - val_loss: 0.0020 - val_acc: 0.3995\n",
            "Epoch 167/500\n",
            " - 4s - loss: 4.5579e-04 - acc: 0.8481 - val_loss: 0.0017 - val_acc: 0.4416\n",
            "Epoch 168/500\n",
            " - 4s - loss: 4.8112e-04 - acc: 0.8353 - val_loss: 0.0016 - val_acc: 0.4112\n",
            "Epoch 169/500\n",
            " - 4s - loss: 4.1949e-04 - acc: 0.8318 - val_loss: 0.0016 - val_acc: 0.4533\n",
            "Epoch 170/500\n",
            " - 4s - loss: 3.9361e-04 - acc: 0.8429 - val_loss: 0.0015 - val_acc: 0.4883\n",
            "Epoch 171/500\n",
            " - 4s - loss: 3.5097e-04 - acc: 0.8318 - val_loss: 0.0015 - val_acc: 0.5187\n",
            "Epoch 172/500\n",
            " - 4s - loss: 3.1467e-04 - acc: 0.8785 - val_loss: 0.0014 - val_acc: 0.4883\n",
            "Epoch 173/500\n",
            " - 4s - loss: 3.6944e-04 - acc: 0.8610 - val_loss: 0.0015 - val_acc: 0.4673\n",
            "Epoch 174/500\n",
            " - 4s - loss: 3.2345e-04 - acc: 0.8540 - val_loss: 0.0014 - val_acc: 0.5327\n",
            "Epoch 175/500\n",
            " - 4s - loss: 3.5419e-04 - acc: 0.8458 - val_loss: 0.0014 - val_acc: 0.5350\n",
            "Epoch 176/500\n",
            " - 4s - loss: 3.2866e-04 - acc: 0.8516 - val_loss: 0.0014 - val_acc: 0.5304\n",
            "Epoch 177/500\n",
            " - 4s - loss: 3.3322e-04 - acc: 0.8557 - val_loss: 0.0014 - val_acc: 0.5350\n",
            "Epoch 178/500\n",
            " - 4s - loss: 2.8955e-04 - acc: 0.8370 - val_loss: 0.0013 - val_acc: 0.4813\n",
            "Epoch 179/500\n",
            " - 4s - loss: 2.9675e-04 - acc: 0.8779 - val_loss: 0.0015 - val_acc: 0.5140\n",
            "Epoch 180/500\n",
            " - 4s - loss: 3.4470e-04 - acc: 0.8604 - val_loss: 0.0015 - val_acc: 0.5280\n",
            "Epoch 181/500\n",
            " - 4s - loss: 3.2550e-04 - acc: 0.8364 - val_loss: 0.0014 - val_acc: 0.5280\n",
            "Epoch 182/500\n",
            " - 4s - loss: 2.9369e-04 - acc: 0.8738 - val_loss: 0.0013 - val_acc: 0.5164\n",
            "Epoch 183/500\n",
            " - 4s - loss: 3.1148e-04 - acc: 0.8616 - val_loss: 0.0013 - val_acc: 0.5117\n",
            "Epoch 184/500\n",
            " - 4s - loss: 2.5482e-04 - acc: 0.8773 - val_loss: 0.0015 - val_acc: 0.5304\n",
            "Epoch 185/500\n",
            " - 4s - loss: 3.1369e-04 - acc: 0.8557 - val_loss: 0.0014 - val_acc: 0.5070\n",
            "Epoch 186/500\n",
            " - 4s - loss: 3.2816e-04 - acc: 0.8271 - val_loss: 0.0014 - val_acc: 0.4883\n",
            "Epoch 187/500\n",
            " - 4s - loss: 3.2498e-04 - acc: 0.8335 - val_loss: 0.0015 - val_acc: 0.5117\n",
            "Epoch 188/500\n",
            " - 4s - loss: 3.2696e-04 - acc: 0.8610 - val_loss: 0.0014 - val_acc: 0.5327\n",
            "Epoch 189/500\n",
            " - 4s - loss: 2.8979e-04 - acc: 0.8633 - val_loss: 0.0013 - val_acc: 0.5257\n",
            "Epoch 190/500\n",
            " - 4s - loss: 3.2903e-04 - acc: 0.8505 - val_loss: 0.0014 - val_acc: 0.4743\n",
            "Epoch 191/500\n",
            " - 4s - loss: 3.2488e-04 - acc: 0.8452 - val_loss: 0.0015 - val_acc: 0.5023\n",
            "Epoch 192/500\n",
            " - 4s - loss: 3.4172e-04 - acc: 0.8522 - val_loss: 0.0014 - val_acc: 0.5187\n",
            "Epoch 193/500\n",
            " - 4s - loss: 3.6557e-04 - acc: 0.8125 - val_loss: 0.0013 - val_acc: 0.5444\n",
            "Epoch 194/500\n",
            " - 4s - loss: 3.2100e-04 - acc: 0.8505 - val_loss: 0.0016 - val_acc: 0.5327\n",
            "Epoch 195/500\n",
            " - 4s - loss: 3.4339e-04 - acc: 0.8370 - val_loss: 0.0013 - val_acc: 0.5491\n",
            "Epoch 196/500\n",
            " - 4s - loss: 3.3722e-04 - acc: 0.8417 - val_loss: 0.0014 - val_acc: 0.5561\n",
            "Epoch 197/500\n",
            " - 4s - loss: 3.1449e-04 - acc: 0.8639 - val_loss: 0.0018 - val_acc: 0.5117\n",
            "Epoch 198/500\n",
            " - 4s - loss: 2.9613e-04 - acc: 0.8452 - val_loss: 0.0015 - val_acc: 0.4907\n",
            "Epoch 199/500\n",
            " - 4s - loss: 2.9989e-04 - acc: 0.8651 - val_loss: 0.0014 - val_acc: 0.4883\n",
            "Epoch 200/500\n",
            " - 4s - loss: 3.3182e-04 - acc: 0.8224 - val_loss: 0.0013 - val_acc: 0.5280\n",
            "Epoch 201/500\n",
            " - 4s - loss: 3.0236e-04 - acc: 0.8662 - val_loss: 0.0013 - val_acc: 0.5070\n",
            "Epoch 202/500\n",
            " - 4s - loss: 3.5490e-04 - acc: 0.8610 - val_loss: 0.0016 - val_acc: 0.5140\n",
            "Epoch 203/500\n",
            " - 4s - loss: 3.3914e-04 - acc: 0.8522 - val_loss: 0.0014 - val_acc: 0.5444\n",
            "Epoch 204/500\n",
            " - 4s - loss: 3.6062e-04 - acc: 0.8505 - val_loss: 0.0014 - val_acc: 0.4743\n",
            "Epoch 205/500\n",
            " - 4s - loss: 3.3599e-04 - acc: 0.8364 - val_loss: 0.0015 - val_acc: 0.4860\n",
            "Epoch 206/500\n",
            " - 4s - loss: 3.8387e-04 - acc: 0.7956 - val_loss: 0.0013 - val_acc: 0.5327\n",
            "Epoch 207/500\n",
            " - 4s - loss: 3.4584e-04 - acc: 0.8470 - val_loss: 0.0014 - val_acc: 0.5257\n",
            "Epoch 208/500\n",
            " - 4s - loss: 3.3882e-04 - acc: 0.8627 - val_loss: 0.0015 - val_acc: 0.5421\n",
            "Epoch 209/500\n",
            " - 4s - loss: 3.5635e-04 - acc: 0.8178 - val_loss: 0.0014 - val_acc: 0.5280\n",
            "Epoch 210/500\n",
            " - 4s - loss: 3.2387e-04 - acc: 0.8347 - val_loss: 0.0014 - val_acc: 0.5000\n",
            "Epoch 211/500\n",
            " - 4s - loss: 2.9012e-04 - acc: 0.8546 - val_loss: 0.0015 - val_acc: 0.5397\n",
            "Epoch 212/500\n",
            " - 4s - loss: 3.0646e-04 - acc: 0.8388 - val_loss: 0.0013 - val_acc: 0.5023\n",
            "Epoch 213/500\n",
            " - 4s - loss: 3.1959e-04 - acc: 0.8662 - val_loss: 0.0014 - val_acc: 0.5397\n",
            "Epoch 214/500\n",
            " - 4s - loss: 3.0764e-04 - acc: 0.8511 - val_loss: 0.0014 - val_acc: 0.5561\n",
            "Epoch 215/500\n",
            " - 4s - loss: 3.2456e-04 - acc: 0.8446 - val_loss: 0.0017 - val_acc: 0.4977\n",
            "Epoch 216/500\n",
            " - 4s - loss: 3.0690e-04 - acc: 0.8925 - val_loss: 0.0015 - val_acc: 0.4556\n",
            "Epoch 217/500\n",
            " - 4s - loss: 3.2640e-04 - acc: 0.8347 - val_loss: 0.0014 - val_acc: 0.4720\n",
            "Epoch 218/500\n",
            " - 4s - loss: 3.2122e-04 - acc: 0.8499 - val_loss: 0.0015 - val_acc: 0.5117\n",
            "Epoch 219/500\n",
            " - 4s - loss: 2.8959e-04 - acc: 0.8522 - val_loss: 0.0014 - val_acc: 0.5304\n",
            "Epoch 220/500\n",
            " - 4s - loss: 2.9869e-04 - acc: 0.8668 - val_loss: 0.0014 - val_acc: 0.5000\n",
            "Epoch 221/500\n",
            " - 4s - loss: 2.8073e-04 - acc: 0.8423 - val_loss: 0.0013 - val_acc: 0.4860\n",
            "Epoch 222/500\n",
            " - 4s - loss: 3.3158e-04 - acc: 0.8224 - val_loss: 0.0015 - val_acc: 0.5444\n",
            "Epoch 223/500\n",
            " - 4s - loss: 3.1203e-04 - acc: 0.8400 - val_loss: 0.0016 - val_acc: 0.4953\n",
            "Epoch 224/500\n",
            " - 4s - loss: 3.3429e-04 - acc: 0.8674 - val_loss: 0.0014 - val_acc: 0.5140\n",
            "Epoch 225/500\n",
            " - 4s - loss: 3.1136e-04 - acc: 0.8803 - val_loss: 0.0014 - val_acc: 0.5537\n",
            "Epoch 226/500\n",
            " - 4s - loss: 2.7899e-04 - acc: 0.8797 - val_loss: 0.0015 - val_acc: 0.5561\n",
            "Epoch 227/500\n",
            " - 4s - loss: 2.8766e-04 - acc: 0.8499 - val_loss: 0.0015 - val_acc: 0.5117\n",
            "Epoch 228/500\n",
            " - 4s - loss: 2.4176e-04 - acc: 0.8481 - val_loss: 0.0014 - val_acc: 0.4766\n",
            "Epoch 229/500\n",
            " - 4s - loss: 2.7507e-04 - acc: 0.8592 - val_loss: 0.0013 - val_acc: 0.5070\n",
            "Epoch 230/500\n",
            " - 4s - loss: 3.1683e-04 - acc: 0.8382 - val_loss: 0.0013 - val_acc: 0.5421\n",
            "Epoch 231/500\n",
            " - 4s - loss: 2.4155e-04 - acc: 0.8610 - val_loss: 0.0013 - val_acc: 0.5140\n",
            "Epoch 232/500\n",
            " - 4s - loss: 2.6305e-04 - acc: 0.8668 - val_loss: 0.0013 - val_acc: 0.5397\n",
            "Epoch 233/500\n",
            " - 4s - loss: 2.6109e-04 - acc: 0.8657 - val_loss: 0.0014 - val_acc: 0.4790\n",
            "Epoch 234/500\n",
            " - 4s - loss: 3.7196e-04 - acc: 0.8621 - val_loss: 0.0014 - val_acc: 0.4743\n",
            "Epoch 235/500\n",
            " - 4s - loss: 3.4887e-04 - acc: 0.8516 - val_loss: 0.0014 - val_acc: 0.4953\n",
            "Epoch 236/500\n",
            " - 4s - loss: 3.1538e-04 - acc: 0.8458 - val_loss: 0.0014 - val_acc: 0.5023\n",
            "Epoch 237/500\n",
            " - 4s - loss: 2.4623e-04 - acc: 0.8797 - val_loss: 0.0012 - val_acc: 0.5210\n",
            "Epoch 238/500\n",
            " - 4s - loss: 2.8238e-04 - acc: 0.8680 - val_loss: 0.0016 - val_acc: 0.5257\n",
            "Epoch 239/500\n",
            " - 4s - loss: 3.0648e-04 - acc: 0.8744 - val_loss: 0.0014 - val_acc: 0.4416\n",
            "Epoch 240/500\n",
            " - 4s - loss: 3.0706e-04 - acc: 0.8645 - val_loss: 0.0012 - val_acc: 0.5093\n",
            "Epoch 241/500\n",
            " - 4s - loss: 2.7785e-04 - acc: 0.8908 - val_loss: 0.0013 - val_acc: 0.5350\n",
            "Epoch 242/500\n",
            " - 4s - loss: 3.4077e-04 - acc: 0.8440 - val_loss: 0.0014 - val_acc: 0.5327\n",
            "Epoch 243/500\n",
            " - 4s - loss: 3.0948e-04 - acc: 0.8271 - val_loss: 0.0013 - val_acc: 0.4790\n",
            "Epoch 244/500\n",
            " - 4s - loss: 2.7185e-04 - acc: 0.8779 - val_loss: 0.0014 - val_acc: 0.5093\n",
            "Epoch 245/500\n",
            " - 4s - loss: 2.9098e-04 - acc: 0.8551 - val_loss: 0.0015 - val_acc: 0.4509\n",
            "Epoch 246/500\n",
            " - 4s - loss: 3.1426e-04 - acc: 0.8598 - val_loss: 0.0014 - val_acc: 0.5093\n",
            "Epoch 247/500\n",
            " - 4s - loss: 2.8702e-04 - acc: 0.8668 - val_loss: 0.0014 - val_acc: 0.5164\n",
            "Epoch 248/500\n",
            " - 4s - loss: 2.8578e-04 - acc: 0.8732 - val_loss: 0.0013 - val_acc: 0.5070\n",
            "Epoch 249/500\n",
            " - 4s - loss: 2.9065e-04 - acc: 0.8610 - val_loss: 0.0014 - val_acc: 0.5234\n",
            "Epoch 250/500\n",
            " - 4s - loss: 3.2606e-04 - acc: 0.8388 - val_loss: 0.0015 - val_acc: 0.4486\n",
            "Epoch 251/500\n",
            " - 4s - loss: 3.2455e-04 - acc: 0.8312 - val_loss: 0.0014 - val_acc: 0.4977\n",
            "Epoch 252/500\n",
            " - 4s - loss: 3.2469e-04 - acc: 0.8160 - val_loss: 0.0013 - val_acc: 0.4977\n",
            "Epoch 253/500\n",
            " - 4s - loss: 3.1562e-04 - acc: 0.8569 - val_loss: 0.0014 - val_acc: 0.5304\n",
            "Epoch 254/500\n",
            " - 4s - loss: 2.7861e-04 - acc: 0.8768 - val_loss: 0.0015 - val_acc: 0.5117\n",
            "Epoch 255/500\n",
            " - 4s - loss: 3.1685e-04 - acc: 0.8195 - val_loss: 0.0015 - val_acc: 0.5023\n",
            "Epoch 256/500\n",
            " - 4s - loss: 2.7381e-04 - acc: 0.8762 - val_loss: 0.0012 - val_acc: 0.5421\n",
            "Epoch 257/500\n",
            " - 4s - loss: 2.8281e-04 - acc: 0.8364 - val_loss: 0.0014 - val_acc: 0.4650\n",
            "Epoch 258/500\n",
            " - 4s - loss: 3.0557e-04 - acc: 0.8516 - val_loss: 0.0016 - val_acc: 0.5374\n",
            "Epoch 259/500\n",
            " - 4s - loss: 2.7508e-04 - acc: 0.8516 - val_loss: 0.0013 - val_acc: 0.5000\n",
            "Epoch 260/500\n",
            " - 4s - loss: 2.8608e-04 - acc: 0.8627 - val_loss: 0.0015 - val_acc: 0.5607\n",
            "Epoch 261/500\n",
            " - 4s - loss: 3.0026e-04 - acc: 0.8388 - val_loss: 0.0012 - val_acc: 0.5561\n",
            "Epoch 262/500\n",
            " - 4s - loss: 2.8467e-04 - acc: 0.8674 - val_loss: 0.0013 - val_acc: 0.5093\n",
            "Epoch 263/500\n",
            " - 4s - loss: 2.4944e-04 - acc: 0.9001 - val_loss: 0.0015 - val_acc: 0.4509\n",
            "Epoch 264/500\n",
            " - 4s - loss: 2.6338e-04 - acc: 0.8808 - val_loss: 0.0013 - val_acc: 0.4743\n",
            "Epoch 265/500\n",
            " - 4s - loss: 2.5114e-04 - acc: 0.9001 - val_loss: 0.0014 - val_acc: 0.5164\n",
            "Epoch 266/500\n",
            " - 4s - loss: 2.5902e-04 - acc: 0.8808 - val_loss: 0.0013 - val_acc: 0.5117\n",
            "Epoch 267/500\n",
            " - 4s - loss: 3.0352e-04 - acc: 0.8458 - val_loss: 0.0014 - val_acc: 0.4790\n",
            "Epoch 268/500\n",
            " - 4s - loss: 2.3013e-04 - acc: 0.8727 - val_loss: 0.0013 - val_acc: 0.4720\n",
            "Epoch 269/500\n",
            " - 4s - loss: 2.3951e-04 - acc: 0.8721 - val_loss: 0.0012 - val_acc: 0.5537\n",
            "Epoch 270/500\n",
            " - 4s - loss: 3.1828e-04 - acc: 0.8528 - val_loss: 0.0015 - val_acc: 0.4696\n",
            "Epoch 271/500\n",
            " - 4s - loss: 2.9485e-04 - acc: 0.8528 - val_loss: 0.0013 - val_acc: 0.5304\n",
            "Epoch 272/500\n",
            " - 4s - loss: 2.7114e-04 - acc: 0.8645 - val_loss: 0.0015 - val_acc: 0.5070\n",
            "Epoch 273/500\n",
            " - 4s - loss: 2.7679e-04 - acc: 0.8744 - val_loss: 0.0015 - val_acc: 0.4766\n",
            "Epoch 274/500\n",
            " - 4s - loss: 3.0265e-04 - acc: 0.8569 - val_loss: 0.0013 - val_acc: 0.5607\n",
            "Epoch 275/500\n",
            " - 4s - loss: 2.5091e-04 - acc: 0.8867 - val_loss: 0.0013 - val_acc: 0.5327\n",
            "Epoch 276/500\n",
            " - 4s - loss: 2.3282e-04 - acc: 0.8814 - val_loss: 0.0013 - val_acc: 0.5023\n",
            "Epoch 277/500\n",
            " - 4s - loss: 2.3731e-04 - acc: 0.8621 - val_loss: 0.0014 - val_acc: 0.5327\n",
            "Epoch 278/500\n",
            " - 4s - loss: 2.7584e-04 - acc: 0.8627 - val_loss: 0.0013 - val_acc: 0.4907\n",
            "Epoch 279/500\n",
            " - 4s - loss: 2.9251e-04 - acc: 0.8557 - val_loss: 0.0013 - val_acc: 0.4977\n",
            "Epoch 280/500\n",
            " - 4s - loss: 2.6739e-04 - acc: 0.8721 - val_loss: 0.0013 - val_acc: 0.5350\n",
            "Epoch 281/500\n",
            " - 4s - loss: 2.9583e-04 - acc: 0.8534 - val_loss: 0.0014 - val_acc: 0.5397\n",
            "Epoch 282/500\n",
            " - 4s - loss: 2.6622e-04 - acc: 0.8610 - val_loss: 0.0014 - val_acc: 0.4720\n",
            "Epoch 283/500\n",
            " - 4s - loss: 2.8504e-04 - acc: 0.8581 - val_loss: 0.0013 - val_acc: 0.4766\n",
            "Epoch 284/500\n",
            " - 4s - loss: 3.0073e-04 - acc: 0.8481 - val_loss: 0.0014 - val_acc: 0.5000\n",
            "Epoch 285/500\n",
            " - 4s - loss: 2.7099e-04 - acc: 0.8744 - val_loss: 0.0014 - val_acc: 0.5350\n",
            "Epoch 286/500\n",
            " - 4s - loss: 2.9538e-04 - acc: 0.8329 - val_loss: 0.0018 - val_acc: 0.5467\n",
            "Epoch 287/500\n",
            " - 4s - loss: 2.8269e-04 - acc: 0.8633 - val_loss: 0.0014 - val_acc: 0.5234\n",
            "Epoch 288/500\n",
            " - 4s - loss: 2.6921e-04 - acc: 0.8499 - val_loss: 0.0013 - val_acc: 0.5397\n",
            "Epoch 289/500\n",
            " - 4s - loss: 2.9344e-04 - acc: 0.8335 - val_loss: 0.0012 - val_acc: 0.5444\n",
            "Epoch 290/500\n",
            " - 4s - loss: 2.4928e-04 - acc: 0.8528 - val_loss: 0.0013 - val_acc: 0.4813\n",
            "Epoch 291/500\n",
            " - 4s - loss: 2.4106e-04 - acc: 0.8621 - val_loss: 0.0015 - val_acc: 0.5140\n",
            "Epoch 292/500\n",
            " - 4s - loss: 2.9094e-04 - acc: 0.8879 - val_loss: 0.0014 - val_acc: 0.5280\n",
            "Epoch 293/500\n",
            " - 4s - loss: 2.5414e-04 - acc: 0.8762 - val_loss: 0.0014 - val_acc: 0.4743\n",
            "Epoch 294/500\n",
            " - 4s - loss: 2.6540e-04 - acc: 0.8470 - val_loss: 0.0014 - val_acc: 0.4907\n",
            "Epoch 295/500\n",
            " - 4s - loss: 2.9305e-04 - acc: 0.8738 - val_loss: 0.0015 - val_acc: 0.5257\n",
            "Epoch 296/500\n",
            " - 4s - loss: 3.1786e-04 - acc: 0.8417 - val_loss: 0.0013 - val_acc: 0.4860\n",
            "Epoch 297/500\n",
            " - 4s - loss: 2.3897e-04 - acc: 0.8779 - val_loss: 0.0013 - val_acc: 0.5234\n",
            "Epoch 298/500\n",
            " - 4s - loss: 2.3080e-04 - acc: 0.8692 - val_loss: 0.0013 - val_acc: 0.5350\n",
            "Epoch 299/500\n",
            " - 4s - loss: 2.7103e-04 - acc: 0.8563 - val_loss: 0.0013 - val_acc: 0.4977\n",
            "Epoch 300/500\n",
            " - 4s - loss: 2.9120e-04 - acc: 0.8744 - val_loss: 0.0012 - val_acc: 0.4836\n",
            "Epoch 301/500\n",
            " - 4s - loss: 2.8795e-04 - acc: 0.8686 - val_loss: 0.0014 - val_acc: 0.5187\n",
            "Epoch 302/500\n",
            " - 4s - loss: 2.9532e-04 - acc: 0.8750 - val_loss: 0.0014 - val_acc: 0.5350\n",
            "Epoch 303/500\n",
            " - 4s - loss: 2.8240e-04 - acc: 0.8797 - val_loss: 0.0012 - val_acc: 0.4579\n",
            "Epoch 304/500\n",
            " - 4s - loss: 3.1344e-04 - acc: 0.8668 - val_loss: 0.0014 - val_acc: 0.5070\n",
            "Epoch 305/500\n",
            " - 4s - loss: 2.8624e-04 - acc: 0.8604 - val_loss: 0.0013 - val_acc: 0.5210\n",
            "Epoch 306/500\n",
            " - 4s - loss: 3.0317e-04 - acc: 0.8370 - val_loss: 0.0014 - val_acc: 0.5000\n",
            "Epoch 307/500\n",
            " - 4s - loss: 2.6687e-04 - acc: 0.8762 - val_loss: 0.0015 - val_acc: 0.5374\n",
            "Epoch 308/500\n",
            " - 4s - loss: 2.4285e-04 - acc: 0.8797 - val_loss: 0.0013 - val_acc: 0.5164\n",
            "Epoch 309/500\n",
            " - 4s - loss: 2.7942e-04 - acc: 0.8277 - val_loss: 0.0016 - val_acc: 0.5164\n",
            "Epoch 310/500\n",
            " - 4s - loss: 2.8254e-04 - acc: 0.8388 - val_loss: 0.0013 - val_acc: 0.4930\n",
            "Epoch 311/500\n",
            " - 4s - loss: 2.2004e-04 - acc: 0.8914 - val_loss: 0.0013 - val_acc: 0.4907\n",
            "Epoch 312/500\n",
            " - 4s - loss: 2.6274e-04 - acc: 0.8773 - val_loss: 0.0012 - val_acc: 0.4790\n",
            "Epoch 313/500\n",
            " - 4s - loss: 2.6130e-04 - acc: 0.8668 - val_loss: 0.0014 - val_acc: 0.5678\n",
            "Epoch 314/500\n",
            " - 4s - loss: 2.3860e-04 - acc: 0.8843 - val_loss: 0.0013 - val_acc: 0.5210\n",
            "Epoch 315/500\n",
            " - 4s - loss: 2.3605e-04 - acc: 0.8902 - val_loss: 0.0013 - val_acc: 0.5654\n",
            "Epoch 316/500\n",
            " - 4s - loss: 2.9343e-04 - acc: 0.8306 - val_loss: 0.0014 - val_acc: 0.5140\n",
            "Epoch 317/500\n",
            " - 4s - loss: 2.7221e-04 - acc: 0.8540 - val_loss: 0.0013 - val_acc: 0.5070\n",
            "Epoch 318/500\n",
            " - 4s - loss: 2.2452e-04 - acc: 0.8697 - val_loss: 0.0013 - val_acc: 0.4977\n",
            "Epoch 319/500\n",
            " - 4s - loss: 2.0314e-04 - acc: 0.8867 - val_loss: 0.0012 - val_acc: 0.4813\n",
            "Epoch 320/500\n",
            " - 4s - loss: 2.3504e-04 - acc: 0.8838 - val_loss: 0.0013 - val_acc: 0.5117\n",
            "Epoch 321/500\n",
            " - 4s - loss: 2.4208e-04 - acc: 0.8884 - val_loss: 0.0012 - val_acc: 0.5444\n",
            "Epoch 322/500\n",
            " - 4s - loss: 2.5389e-04 - acc: 0.8586 - val_loss: 0.0013 - val_acc: 0.5280\n",
            "Epoch 323/500\n",
            " - 4s - loss: 2.7716e-04 - acc: 0.8756 - val_loss: 0.0015 - val_acc: 0.5093\n",
            "Epoch 324/500\n",
            " - 4s - loss: 2.9316e-04 - acc: 0.8727 - val_loss: 0.0013 - val_acc: 0.5164\n",
            "Epoch 325/500\n",
            " - 4s - loss: 2.3969e-04 - acc: 0.8680 - val_loss: 0.0014 - val_acc: 0.4743\n",
            "Epoch 326/500\n",
            " - 4s - loss: 2.4230e-04 - acc: 0.8715 - val_loss: 0.0013 - val_acc: 0.4860\n",
            "Epoch 327/500\n",
            " - 4s - loss: 2.2972e-04 - acc: 0.8884 - val_loss: 0.0015 - val_acc: 0.4907\n",
            "Epoch 328/500\n",
            " - 4s - loss: 2.0376e-04 - acc: 0.8814 - val_loss: 0.0013 - val_acc: 0.5257\n",
            "Epoch 329/500\n",
            " - 4s - loss: 2.4043e-04 - acc: 0.8674 - val_loss: 0.0013 - val_acc: 0.5467\n",
            "Epoch 330/500\n",
            " - 4s - loss: 2.3647e-04 - acc: 0.8668 - val_loss: 0.0012 - val_acc: 0.5280\n",
            "Epoch 331/500\n",
            " - 4s - loss: 2.4728e-04 - acc: 0.8668 - val_loss: 0.0012 - val_acc: 0.5631\n",
            "Epoch 332/500\n",
            " - 4s - loss: 1.9510e-04 - acc: 0.8803 - val_loss: 0.0012 - val_acc: 0.5210\n",
            "Epoch 333/500\n",
            " - 4s - loss: 2.3415e-04 - acc: 0.8709 - val_loss: 0.0012 - val_acc: 0.5584\n",
            "Epoch 334/500\n",
            " - 4s - loss: 2.1633e-04 - acc: 0.8715 - val_loss: 0.0014 - val_acc: 0.4836\n",
            "Epoch 335/500\n",
            " - 4s - loss: 2.2493e-04 - acc: 0.8627 - val_loss: 0.0014 - val_acc: 0.4650\n",
            "Epoch 336/500\n",
            " - 4s - loss: 2.4760e-04 - acc: 0.8925 - val_loss: 0.0013 - val_acc: 0.5000\n",
            "Epoch 337/500\n",
            " - 4s - loss: 2.4818e-04 - acc: 0.8838 - val_loss: 0.0012 - val_acc: 0.5234\n",
            "Epoch 338/500\n",
            " - 4s - loss: 2.2515e-04 - acc: 0.8925 - val_loss: 0.0013 - val_acc: 0.5234\n",
            "Epoch 339/500\n",
            " - 4s - loss: 2.2605e-04 - acc: 0.8820 - val_loss: 0.0013 - val_acc: 0.5257\n",
            "Epoch 340/500\n",
            " - 4s - loss: 2.8207e-04 - acc: 0.8610 - val_loss: 0.0014 - val_acc: 0.5023\n",
            "Epoch 341/500\n",
            " - 4s - loss: 2.2581e-04 - acc: 0.8627 - val_loss: 0.0013 - val_acc: 0.5631\n",
            "Epoch 342/500\n",
            " - 4s - loss: 2.4977e-04 - acc: 0.8458 - val_loss: 0.0016 - val_acc: 0.5444\n",
            "Epoch 343/500\n",
            " - 4s - loss: 2.9178e-04 - acc: 0.8586 - val_loss: 0.0014 - val_acc: 0.4930\n",
            "Epoch 344/500\n",
            " - 4s - loss: 2.2170e-04 - acc: 0.8616 - val_loss: 0.0013 - val_acc: 0.5467\n",
            "Epoch 345/500\n",
            " - 4s - loss: 2.4572e-04 - acc: 0.8686 - val_loss: 0.0014 - val_acc: 0.5374\n",
            "Epoch 346/500\n",
            " - 4s - loss: 2.7935e-04 - acc: 0.8505 - val_loss: 0.0013 - val_acc: 0.5327\n",
            "Epoch 347/500\n",
            " - 4s - loss: 2.3203e-04 - acc: 0.8849 - val_loss: 0.0014 - val_acc: 0.4743\n",
            "Epoch 348/500\n",
            " - 4s - loss: 2.2068e-04 - acc: 0.8744 - val_loss: 0.0013 - val_acc: 0.4813\n",
            "Epoch 349/500\n",
            " - 4s - loss: 2.3800e-04 - acc: 0.8686 - val_loss: 0.0013 - val_acc: 0.5350\n",
            "Epoch 350/500\n",
            " - 4s - loss: 2.1824e-04 - acc: 0.8499 - val_loss: 0.0015 - val_acc: 0.4930\n",
            "Epoch 351/500\n",
            " - 4s - loss: 2.3124e-04 - acc: 0.8709 - val_loss: 0.0013 - val_acc: 0.5491\n",
            "Epoch 352/500\n",
            " - 4s - loss: 2.1549e-04 - acc: 0.8557 - val_loss: 0.0013 - val_acc: 0.5631\n",
            "Epoch 353/500\n",
            " - 4s - loss: 2.0205e-04 - acc: 0.8960 - val_loss: 0.0013 - val_acc: 0.5047\n",
            "Epoch 354/500\n",
            " - 4s - loss: 1.9900e-04 - acc: 0.8855 - val_loss: 0.0012 - val_acc: 0.4766\n",
            "Epoch 355/500\n",
            " - 4s - loss: 2.0695e-04 - acc: 0.8616 - val_loss: 0.0014 - val_acc: 0.4743\n",
            "Epoch 356/500\n",
            " - 4s - loss: 2.6184e-04 - acc: 0.8814 - val_loss: 0.0014 - val_acc: 0.5047\n",
            "Epoch 357/500\n",
            " - 4s - loss: 2.5406e-04 - acc: 0.8779 - val_loss: 0.0014 - val_acc: 0.5374\n",
            "Epoch 358/500\n",
            " - 4s - loss: 2.2505e-04 - acc: 0.8773 - val_loss: 0.0013 - val_acc: 0.5724\n",
            "Epoch 359/500\n",
            " - 4s - loss: 2.1312e-04 - acc: 0.8826 - val_loss: 0.0012 - val_acc: 0.5537\n",
            "Epoch 360/500\n",
            " - 4s - loss: 2.3124e-04 - acc: 0.8709 - val_loss: 0.0013 - val_acc: 0.5280\n",
            "Epoch 361/500\n",
            " - 4s - loss: 2.4272e-04 - acc: 0.8522 - val_loss: 0.0013 - val_acc: 0.4930\n",
            "Epoch 362/500\n",
            " - 4s - loss: 2.5389e-04 - acc: 0.8814 - val_loss: 0.0015 - val_acc: 0.5070\n",
            "Epoch 363/500\n",
            " - 4s - loss: 2.2256e-04 - acc: 0.8680 - val_loss: 0.0013 - val_acc: 0.4813\n",
            "Epoch 364/500\n",
            " - 4s - loss: 2.5666e-04 - acc: 0.8744 - val_loss: 0.0014 - val_acc: 0.5093\n",
            "Epoch 365/500\n",
            " - 4s - loss: 2.5524e-04 - acc: 0.8721 - val_loss: 0.0013 - val_acc: 0.5187\n",
            "Epoch 366/500\n",
            " - 4s - loss: 2.5103e-04 - acc: 0.8592 - val_loss: 0.0015 - val_acc: 0.4509\n",
            "Epoch 367/500\n",
            " - 4s - loss: 2.4079e-04 - acc: 0.8423 - val_loss: 0.0013 - val_acc: 0.4556\n",
            "Epoch 368/500\n",
            " - 4s - loss: 2.7709e-04 - acc: 0.8657 - val_loss: 0.0014 - val_acc: 0.4907\n",
            "Epoch 369/500\n",
            " - 4s - loss: 2.6279e-04 - acc: 0.8838 - val_loss: 0.0014 - val_acc: 0.5584\n",
            "Epoch 370/500\n",
            " - 4s - loss: 2.4280e-04 - acc: 0.8592 - val_loss: 0.0013 - val_acc: 0.5514\n",
            "Epoch 371/500\n",
            " - 4s - loss: 2.1842e-04 - acc: 0.8820 - val_loss: 0.0013 - val_acc: 0.4696\n",
            "Epoch 372/500\n",
            " - 4s - loss: 1.9002e-04 - acc: 0.8768 - val_loss: 0.0013 - val_acc: 0.4907\n",
            "Epoch 373/500\n",
            " - 4s - loss: 2.2836e-04 - acc: 0.8423 - val_loss: 0.0014 - val_acc: 0.4696\n",
            "Epoch 374/500\n",
            " - 4s - loss: 2.3980e-04 - acc: 0.8610 - val_loss: 0.0013 - val_acc: 0.5000\n",
            "Epoch 375/500\n",
            " - 4s - loss: 2.2875e-04 - acc: 0.8972 - val_loss: 0.0013 - val_acc: 0.5607\n",
            "Epoch 376/500\n",
            " - 4s - loss: 2.3035e-04 - acc: 0.8820 - val_loss: 0.0013 - val_acc: 0.5374\n",
            "Epoch 377/500\n",
            " - 4s - loss: 2.6578e-04 - acc: 0.8627 - val_loss: 0.0014 - val_acc: 0.5000\n",
            "Epoch 378/500\n",
            " - 4s - loss: 2.7631e-04 - acc: 0.8645 - val_loss: 0.0013 - val_acc: 0.4836\n",
            "Epoch 379/500\n",
            " - 4s - loss: 2.2075e-04 - acc: 0.8756 - val_loss: 0.0013 - val_acc: 0.5210\n",
            "Epoch 380/500\n",
            " - 4s - loss: 1.9821e-04 - acc: 0.8744 - val_loss: 0.0013 - val_acc: 0.5537\n",
            "Epoch 381/500\n",
            " - 4s - loss: 2.2799e-04 - acc: 0.8633 - val_loss: 0.0014 - val_acc: 0.5304\n",
            "Epoch 382/500\n",
            " - 4s - loss: 2.3038e-04 - acc: 0.8692 - val_loss: 0.0014 - val_acc: 0.5093\n",
            "Epoch 383/500\n",
            " - 4s - loss: 2.1504e-04 - acc: 0.8843 - val_loss: 0.0013 - val_acc: 0.4673\n",
            "Epoch 384/500\n",
            " - 4s - loss: 2.1978e-04 - acc: 0.8686 - val_loss: 0.0013 - val_acc: 0.5444\n",
            "Epoch 385/500\n",
            " - 4s - loss: 2.1805e-04 - acc: 0.8814 - val_loss: 0.0013 - val_acc: 0.5164\n",
            "Epoch 386/500\n",
            " - 4s - loss: 2.5566e-04 - acc: 0.8703 - val_loss: 0.0013 - val_acc: 0.5070\n",
            "Epoch 387/500\n",
            " - 4s - loss: 2.0291e-04 - acc: 0.8849 - val_loss: 0.0013 - val_acc: 0.4486\n",
            "Epoch 388/500\n",
            " - 4s - loss: 2.1809e-04 - acc: 0.8505 - val_loss: 0.0016 - val_acc: 0.4907\n",
            "Epoch 389/500\n",
            " - 4s - loss: 2.0270e-04 - acc: 0.9019 - val_loss: 0.0013 - val_acc: 0.4579\n",
            "Epoch 390/500\n",
            " - 4s - loss: 2.0264e-04 - acc: 0.8732 - val_loss: 0.0014 - val_acc: 0.4766\n",
            "Epoch 391/500\n",
            " - 4s - loss: 2.2086e-04 - acc: 0.8680 - val_loss: 0.0013 - val_acc: 0.5280\n",
            "Epoch 392/500\n",
            " - 4s - loss: 2.2857e-04 - acc: 0.8318 - val_loss: 0.0013 - val_acc: 0.4673\n",
            "Epoch 393/500\n",
            " - 4s - loss: 2.0817e-04 - acc: 0.8744 - val_loss: 0.0013 - val_acc: 0.4790\n",
            "Epoch 394/500\n",
            " - 4s - loss: 2.1104e-04 - acc: 0.8715 - val_loss: 0.0013 - val_acc: 0.5841\n",
            "Epoch 395/500\n",
            " - 4s - loss: 2.5118e-04 - acc: 0.8855 - val_loss: 0.0013 - val_acc: 0.5678\n",
            "Epoch 396/500\n",
            " - 4s - loss: 1.8660e-04 - acc: 0.8773 - val_loss: 0.0012 - val_acc: 0.4790\n",
            "Epoch 397/500\n",
            " - 4s - loss: 1.9847e-04 - acc: 0.8902 - val_loss: 0.0013 - val_acc: 0.4930\n",
            "Epoch 398/500\n",
            " - 4s - loss: 1.9326e-04 - acc: 0.8773 - val_loss: 0.0012 - val_acc: 0.5374\n",
            "Epoch 399/500\n",
            " - 4s - loss: 2.0642e-04 - acc: 0.8721 - val_loss: 0.0013 - val_acc: 0.5537\n",
            "Epoch 400/500\n",
            " - 4s - loss: 2.1334e-04 - acc: 0.8662 - val_loss: 0.0014 - val_acc: 0.4696\n",
            "Epoch 401/500\n",
            " - 4s - loss: 2.7381e-04 - acc: 0.8744 - val_loss: 0.0013 - val_acc: 0.5257\n",
            "Epoch 402/500\n",
            " - 4s - loss: 2.2283e-04 - acc: 0.8832 - val_loss: 0.0014 - val_acc: 0.5164\n",
            "Epoch 403/500\n",
            " - 4s - loss: 2.5479e-04 - acc: 0.8914 - val_loss: 0.0014 - val_acc: 0.4860\n",
            "Epoch 404/500\n",
            " - 4s - loss: 2.5410e-04 - acc: 0.8551 - val_loss: 0.0013 - val_acc: 0.4930\n",
            "Epoch 405/500\n",
            " - 4s - loss: 2.1597e-04 - acc: 0.8768 - val_loss: 0.0013 - val_acc: 0.5491\n",
            "Epoch 406/500\n",
            " - 4s - loss: 2.2025e-04 - acc: 0.8779 - val_loss: 0.0013 - val_acc: 0.5678\n",
            "Epoch 407/500\n",
            " - 4s - loss: 2.0819e-04 - acc: 0.8884 - val_loss: 0.0012 - val_acc: 0.5374\n",
            "Epoch 408/500\n",
            " - 4s - loss: 1.9391e-04 - acc: 0.8686 - val_loss: 0.0012 - val_acc: 0.5000\n",
            "Epoch 409/500\n",
            " - 4s - loss: 2.6053e-04 - acc: 0.8452 - val_loss: 0.0014 - val_acc: 0.5140\n",
            "Epoch 410/500\n",
            " - 4s - loss: 2.6738e-04 - acc: 0.8621 - val_loss: 0.0015 - val_acc: 0.4603\n",
            "Epoch 411/500\n",
            " - 4s - loss: 2.1992e-04 - acc: 0.8697 - val_loss: 0.0014 - val_acc: 0.5047\n",
            "Epoch 412/500\n",
            " - 4s - loss: 2.1404e-04 - acc: 0.8639 - val_loss: 0.0013 - val_acc: 0.4953\n",
            "Epoch 413/500\n",
            " - 4s - loss: 2.2861e-04 - acc: 0.8814 - val_loss: 0.0013 - val_acc: 0.4766\n",
            "Epoch 414/500\n",
            " - 4s - loss: 1.9571e-04 - acc: 0.8686 - val_loss: 0.0012 - val_acc: 0.5093\n",
            "Epoch 415/500\n",
            " - 4s - loss: 2.3271e-04 - acc: 0.8686 - val_loss: 0.0012 - val_acc: 0.4743\n",
            "Epoch 416/500\n",
            " - 4s - loss: 1.7965e-04 - acc: 0.8966 - val_loss: 0.0014 - val_acc: 0.4907\n",
            "Epoch 417/500\n",
            " - 4s - loss: 2.2384e-04 - acc: 0.8645 - val_loss: 0.0012 - val_acc: 0.5397\n",
            "Epoch 418/500\n",
            " - 4s - loss: 1.8556e-04 - acc: 0.8949 - val_loss: 0.0013 - val_acc: 0.4813\n",
            "Epoch 419/500\n",
            " - 4s - loss: 2.2678e-04 - acc: 0.8791 - val_loss: 0.0013 - val_acc: 0.4533\n",
            "Epoch 420/500\n",
            " - 4s - loss: 2.4599e-04 - acc: 0.8563 - val_loss: 0.0014 - val_acc: 0.5234\n",
            "Epoch 421/500\n",
            " - 4s - loss: 2.3698e-04 - acc: 0.8773 - val_loss: 0.0013 - val_acc: 0.4486\n",
            "Epoch 422/500\n",
            " - 4s - loss: 1.9833e-04 - acc: 0.8791 - val_loss: 0.0013 - val_acc: 0.4836\n",
            "Epoch 423/500\n",
            " - 4s - loss: 2.1805e-04 - acc: 0.8516 - val_loss: 0.0013 - val_acc: 0.5047\n",
            "Epoch 424/500\n",
            " - 4s - loss: 2.1330e-04 - acc: 0.8867 - val_loss: 0.0013 - val_acc: 0.5093\n",
            "Epoch 425/500\n",
            " - 4s - loss: 1.8156e-04 - acc: 0.8732 - val_loss: 0.0013 - val_acc: 0.4766\n",
            "Epoch 426/500\n",
            " - 4s - loss: 2.0443e-04 - acc: 0.8954 - val_loss: 0.0013 - val_acc: 0.4790\n",
            "Epoch 427/500\n",
            " - 4s - loss: 1.7776e-04 - acc: 0.8849 - val_loss: 0.0013 - val_acc: 0.5327\n",
            "Epoch 428/500\n",
            " - 4s - loss: 2.2997e-04 - acc: 0.8721 - val_loss: 0.0012 - val_acc: 0.4860\n",
            "Epoch 429/500\n",
            " - 4s - loss: 1.9979e-04 - acc: 0.8931 - val_loss: 0.0013 - val_acc: 0.5771\n",
            "Epoch 430/500\n",
            " - 4s - loss: 2.2462e-04 - acc: 0.8586 - val_loss: 0.0014 - val_acc: 0.5093\n",
            "Epoch 431/500\n",
            " - 4s - loss: 2.1321e-04 - acc: 0.8808 - val_loss: 0.0012 - val_acc: 0.4930\n",
            "Epoch 432/500\n",
            " - 4s - loss: 2.0565e-04 - acc: 0.8855 - val_loss: 0.0014 - val_acc: 0.5070\n",
            "Epoch 433/500\n",
            " - 4s - loss: 2.5891e-04 - acc: 0.8557 - val_loss: 0.0013 - val_acc: 0.5304\n",
            "Epoch 434/500\n",
            " - 4s - loss: 1.9817e-04 - acc: 0.8890 - val_loss: 0.0014 - val_acc: 0.4953\n",
            "Epoch 435/500\n",
            " - 4s - loss: 1.9365e-04 - acc: 0.8581 - val_loss: 0.0013 - val_acc: 0.5397\n",
            "Epoch 436/500\n",
            " - 4s - loss: 2.1260e-04 - acc: 0.8779 - val_loss: 0.0014 - val_acc: 0.4977\n",
            "Epoch 437/500\n",
            " - 4s - loss: 2.0926e-04 - acc: 0.8581 - val_loss: 0.0013 - val_acc: 0.5304\n",
            "Epoch 438/500\n",
            " - 4s - loss: 1.8255e-04 - acc: 0.8978 - val_loss: 0.0013 - val_acc: 0.4790\n",
            "Epoch 439/500\n",
            " - 4s - loss: 2.1354e-04 - acc: 0.8633 - val_loss: 0.0013 - val_acc: 0.4743\n",
            "Epoch 440/500\n",
            " - 4s - loss: 1.8571e-04 - acc: 0.8943 - val_loss: 0.0014 - val_acc: 0.4790\n",
            "Epoch 441/500\n",
            " - 4s - loss: 2.2258e-04 - acc: 0.8511 - val_loss: 0.0014 - val_acc: 0.4486\n",
            "Epoch 442/500\n",
            " - 4s - loss: 2.0584e-04 - acc: 0.8803 - val_loss: 0.0013 - val_acc: 0.4743\n",
            "Epoch 443/500\n",
            " - 4s - loss: 2.2380e-04 - acc: 0.8563 - val_loss: 0.0014 - val_acc: 0.5304\n",
            "Epoch 444/500\n",
            " - 4s - loss: 2.5695e-04 - acc: 0.8505 - val_loss: 0.0014 - val_acc: 0.4766\n",
            "Epoch 445/500\n",
            " - 4s - loss: 1.8936e-04 - acc: 0.8627 - val_loss: 0.0013 - val_acc: 0.5421\n",
            "Epoch 446/500\n",
            " - 4s - loss: 2.1733e-04 - acc: 0.8610 - val_loss: 0.0013 - val_acc: 0.4766\n",
            "Epoch 447/500\n",
            " - 4s - loss: 2.0965e-04 - acc: 0.9030 - val_loss: 0.0014 - val_acc: 0.4556\n",
            "Epoch 448/500\n",
            " - 4s - loss: 2.2208e-04 - acc: 0.8989 - val_loss: 0.0014 - val_acc: 0.5117\n",
            "Epoch 449/500\n",
            " - 4s - loss: 2.0237e-04 - acc: 0.9065 - val_loss: 0.0013 - val_acc: 0.5537\n",
            "Epoch 450/500\n",
            " - 4s - loss: 1.7742e-04 - acc: 0.8978 - val_loss: 0.0013 - val_acc: 0.4953\n",
            "Epoch 451/500\n",
            " - 4s - loss: 2.3965e-04 - acc: 0.8884 - val_loss: 0.0014 - val_acc: 0.5093\n",
            "Epoch 452/500\n",
            " - 4s - loss: 1.7773e-04 - acc: 0.8744 - val_loss: 0.0013 - val_acc: 0.5070\n",
            "Epoch 453/500\n",
            " - 4s - loss: 2.0620e-04 - acc: 0.8493 - val_loss: 0.0014 - val_acc: 0.4860\n",
            "Epoch 454/500\n",
            " - 4s - loss: 2.0290e-04 - acc: 0.8762 - val_loss: 0.0012 - val_acc: 0.5047\n",
            "Epoch 455/500\n",
            " - 4s - loss: 1.8131e-04 - acc: 0.8861 - val_loss: 0.0013 - val_acc: 0.4907\n",
            "Epoch 456/500\n",
            " - 4s - loss: 1.8861e-04 - acc: 0.8861 - val_loss: 0.0013 - val_acc: 0.5117\n",
            "Epoch 457/500\n",
            " - 4s - loss: 1.9014e-04 - acc: 0.8843 - val_loss: 0.0013 - val_acc: 0.4930\n",
            "Epoch 458/500\n",
            " - 4s - loss: 1.9053e-04 - acc: 0.8744 - val_loss: 0.0013 - val_acc: 0.5607\n",
            "Epoch 459/500\n",
            " - 4s - loss: 1.7968e-04 - acc: 0.8861 - val_loss: 0.0012 - val_acc: 0.5070\n",
            "Epoch 460/500\n",
            " - 4s - loss: 1.7974e-04 - acc: 0.8808 - val_loss: 0.0013 - val_acc: 0.4977\n",
            "Epoch 461/500\n",
            " - 4s - loss: 1.9800e-04 - acc: 0.8902 - val_loss: 0.0013 - val_acc: 0.4813\n",
            "Epoch 462/500\n",
            " - 4s - loss: 1.7312e-04 - acc: 0.8879 - val_loss: 0.0013 - val_acc: 0.4977\n",
            "Epoch 463/500\n",
            " - 4s - loss: 1.9597e-04 - acc: 0.8966 - val_loss: 0.0013 - val_acc: 0.4953\n",
            "Epoch 464/500\n",
            " - 4s - loss: 2.3610e-04 - acc: 0.8604 - val_loss: 0.0013 - val_acc: 0.5187\n",
            "Epoch 465/500\n",
            " - 4s - loss: 1.9434e-04 - acc: 0.8838 - val_loss: 0.0012 - val_acc: 0.5327\n",
            "Epoch 466/500\n",
            " - 4s - loss: 1.8447e-04 - acc: 0.8680 - val_loss: 0.0013 - val_acc: 0.5421\n",
            "Epoch 467/500\n",
            " - 4s - loss: 2.2287e-04 - acc: 0.8546 - val_loss: 0.0013 - val_acc: 0.4860\n",
            "Epoch 468/500\n",
            " - 4s - loss: 1.8326e-04 - acc: 0.8978 - val_loss: 0.0013 - val_acc: 0.5187\n",
            "Epoch 469/500\n",
            " - 4s - loss: 1.9413e-04 - acc: 0.8732 - val_loss: 0.0013 - val_acc: 0.4836\n",
            "Epoch 470/500\n",
            " - 4s - loss: 1.7951e-04 - acc: 0.8768 - val_loss: 0.0012 - val_acc: 0.4860\n",
            "Epoch 471/500\n",
            " - 4s - loss: 1.8670e-04 - acc: 0.8797 - val_loss: 0.0013 - val_acc: 0.5164\n",
            "Epoch 472/500\n",
            " - 4s - loss: 1.9803e-04 - acc: 0.8808 - val_loss: 0.0013 - val_acc: 0.5234\n",
            "Epoch 473/500\n",
            " - 4s - loss: 1.9669e-04 - acc: 0.8931 - val_loss: 0.0013 - val_acc: 0.4930\n",
            "Epoch 474/500\n",
            " - 4s - loss: 1.9487e-04 - acc: 0.8797 - val_loss: 0.0013 - val_acc: 0.5164\n",
            "Epoch 475/500\n",
            " - 4s - loss: 2.1984e-04 - acc: 0.8715 - val_loss: 0.0015 - val_acc: 0.5397\n",
            "Epoch 476/500\n",
            " - 4s - loss: 2.0303e-04 - acc: 0.8925 - val_loss: 0.0013 - val_acc: 0.5280\n",
            "Epoch 477/500\n",
            " - 4s - loss: 1.8439e-04 - acc: 0.8814 - val_loss: 0.0013 - val_acc: 0.5164\n",
            "Epoch 478/500\n",
            " - 4s - loss: 1.9626e-04 - acc: 0.9013 - val_loss: 0.0013 - val_acc: 0.5514\n",
            "Epoch 479/500\n",
            " - 4s - loss: 1.7278e-04 - acc: 0.8989 - val_loss: 0.0013 - val_acc: 0.5397\n",
            "Epoch 480/500\n",
            " - 4s - loss: 2.0551e-04 - acc: 0.8744 - val_loss: 0.0013 - val_acc: 0.5234\n",
            "Epoch 481/500\n",
            " - 4s - loss: 1.8889e-04 - acc: 0.8762 - val_loss: 0.0013 - val_acc: 0.4579\n",
            "Epoch 482/500\n",
            " - 4s - loss: 2.0040e-04 - acc: 0.8727 - val_loss: 0.0013 - val_acc: 0.5631\n",
            "Epoch 483/500\n",
            " - 4s - loss: 1.9657e-04 - acc: 0.8843 - val_loss: 0.0012 - val_acc: 0.5327\n",
            "Epoch 484/500\n",
            " - 4s - loss: 1.5535e-04 - acc: 0.8954 - val_loss: 0.0014 - val_acc: 0.5000\n",
            "Epoch 485/500\n",
            " - 4s - loss: 1.7664e-04 - acc: 0.8884 - val_loss: 0.0013 - val_acc: 0.4696\n",
            "Epoch 486/500\n",
            " - 4s - loss: 1.7405e-04 - acc: 0.8919 - val_loss: 0.0012 - val_acc: 0.4790\n",
            "Epoch 487/500\n",
            " - 4s - loss: 1.8420e-04 - acc: 0.8703 - val_loss: 0.0012 - val_acc: 0.4673\n",
            "Epoch 488/500\n",
            " - 4s - loss: 1.9021e-04 - acc: 0.9036 - val_loss: 0.0013 - val_acc: 0.4813\n",
            "Epoch 489/500\n",
            " - 4s - loss: 1.7463e-04 - acc: 0.8785 - val_loss: 0.0012 - val_acc: 0.5210\n",
            "Epoch 490/500\n",
            " - 4s - loss: 1.8650e-04 - acc: 0.9060 - val_loss: 0.0013 - val_acc: 0.4836\n",
            "Epoch 491/500\n",
            " - 4s - loss: 1.9171e-04 - acc: 0.8937 - val_loss: 0.0012 - val_acc: 0.5000\n",
            "Epoch 492/500\n",
            " - 4s - loss: 1.8634e-04 - acc: 0.8890 - val_loss: 0.0012 - val_acc: 0.5607\n",
            "Epoch 493/500\n",
            " - 4s - loss: 1.8922e-04 - acc: 0.8949 - val_loss: 0.0014 - val_acc: 0.5678\n",
            "Epoch 494/500\n",
            " - 4s - loss: 1.8697e-04 - acc: 0.9065 - val_loss: 0.0014 - val_acc: 0.5140\n",
            "Epoch 495/500\n",
            " - 4s - loss: 1.4781e-04 - acc: 0.8873 - val_loss: 0.0013 - val_acc: 0.5304\n",
            "Epoch 496/500\n",
            " - 4s - loss: 1.6023e-04 - acc: 0.8843 - val_loss: 0.0014 - val_acc: 0.4720\n",
            "Epoch 497/500\n",
            " - 4s - loss: 1.7963e-04 - acc: 0.8814 - val_loss: 0.0013 - val_acc: 0.4860\n",
            "Epoch 498/500\n",
            " - 4s - loss: 1.7881e-04 - acc: 0.8867 - val_loss: 0.0013 - val_acc: 0.5444\n",
            "Epoch 499/500\n",
            " - 4s - loss: 1.7906e-04 - acc: 0.8721 - val_loss: 0.0012 - val_acc: 0.4696\n",
            "Epoch 500/500\n",
            " - 4s - loss: 1.7593e-04 - acc: 0.9025 - val_loss: 0.0013 - val_acc: 0.5280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae3J6_8reoP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}